{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-23T00:31:00.059524Z","iopub.execute_input":"2025-09-23T00:31:00.059807Z","iopub.status.idle":"2025-09-23T00:31:02.115412Z","shell.execute_reply.started":"2025-09-23T00:31:00.059772Z","shell.execute_reply":"2025-09-23T00:31:02.114585Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"**Point Wise**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Data\ndata = pd.DataFrame({\n    \"query_id\": [1, 1, 1, 2, 2, 2],\n    \"f1\": [0.1, 0.4, 0.3, 0.9, 0.2, 0.5],\n    \"f2\": [0.7, 0.1, 0.4, 0.2, 0.9, 0.6],\n    \"relevance\": [3, 2, 1, 2, 3, 0]  # nhãn: 0-3\n})\n\nX = data[[\"f1\", \"f2\"]]\ny = data[\"relevance\"]\n\n# Học mô hình hồi quy\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Dự đoán relevance\ndata[\"pred_score\"] = model.predict(X)\nprint(\"Kết quả dự đoán\")\nprint(data[[\"query_id\", \"f1\", \"f2\", \"relevance\", \"pred_score\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T00:33:35.040403Z","iopub.execute_input":"2025-09-23T00:33:35.040785Z","iopub.status.idle":"2025-09-23T00:33:35.060449Z","shell.execute_reply.started":"2025-09-23T00:33:35.040758Z","shell.execute_reply":"2025-09-23T00:33:35.059366Z"}},"outputs":[{"name":"stdout","text":"Kết quả dự đoán\n   query_id   f1   f2  relevance  pred_score\n0         1  0.1  0.7          3    2.287212\n1         1  0.4  0.1          2    1.728372\n2         1  0.3  0.4          1    1.942033\n3         2  0.9  0.2          2    1.098165\n4         2  0.2  0.9          3    2.210457\n5         2  0.5  0.6          0    1.733761\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"**Pairwise**","metadata":{}},{"cell_type":"markdown","source":"* Xem bài toán như so sánh cặp document trong cùng querry , mục đích là để so sánh xem document nào sẽ rank cao hơn","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom itertools import combinations\n\n# Data\npairs = []\nlabels = []\n\nfor qid in data[\"query_id\"].unique():\n    docs = data[data[\"query_id\"] == qid]\n    for (i, di), (j, dj) in combinations(docs.iterrows(), 2):\n        diff = di[[\"f1\", \"f2\"]] - dj[[\"f1\", \"f2\"]]\n        label = 1 if di[\"relevance\"] > dj[\"relevance\"] else 0\n        pairs.append(diff.values)\n        labels.append(label)\n\nX_pairs = np.vstack(pairs)\ny_pairs = np.array(labels)\n\n# Train logistic regression \npair_model = LogisticRegression()\npair_model.fit(X_pairs, y_pairs)\n\nprint(\"Pairwise model accuracy:\", pair_model.score(X_pairs, y_pairs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T00:34:57.257684Z","iopub.execute_input":"2025-09-23T00:34:57.258044Z","iopub.status.idle":"2025-09-23T00:34:57.283432Z","shell.execute_reply.started":"2025-09-23T00:34:57.258016Z","shell.execute_reply":"2025-09-23T00:34:57.282628Z"}},"outputs":[{"name":"stdout","text":"Pairwise model accuracy: 0.8333333333333334\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import xgboost as xgb\n\n# Data\nX = data[[\"f1\", \"f2\"]].values\ny = data[\"relevance\"].values\ngroup = data.groupby(\"query_id\").size().to_list() \n\ndtrain = xgb.DMatrix(X, label=y)\ndtrain.set_group(group)\n\nparams = {\n    \"objective\": \"rank:ndcg\",   # Listwise loss\n    \"eval_metric\": \"ndcg\",\n    \"eta\": 0.1,\n    \"max_depth\": 3\n}\n\nrank_model = xgb.train(params, dtrain, num_boost_round=20)\n\n# Dự đoán\ndata[\"pred_score\"] = rank_model.predict(dtrain)\nprint(data[[\"query_id\", \"relevance\", \"pred_score\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T00:35:47.889150Z","iopub.execute_input":"2025-09-23T00:35:47.889544Z","iopub.status.idle":"2025-09-23T00:35:48.251793Z","shell.execute_reply.started":"2025-09-23T00:35:47.889519Z","shell.execute_reply":"2025-09-23T00:35:48.250198Z"}},"outputs":[{"name":"stdout","text":"   query_id  relevance    pred_score\n0         1          3  1.310156e-08\n1         1          2  1.310156e-08\n2         1          1  1.310156e-08\n3         2          2  1.310156e-08\n4         2          3  1.310156e-08\n5         2          0  1.310156e-08\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}